# check
import os
import csv
import requests
import time
import hashlib

# è®¾ç½®åŸºæœ¬è·¯å¾„
ROUND_DIR = "backend/round/61627"
LINEUP_DIR = "backend/data/lineup"
API_URL_TEMPLATE = "https://www.sofascore.com/api/v1/event/{match_id}/lineups"

# å¤±è´¥æ¯”èµ›åˆ—è¡¨
failed_matches = []

def create_directory(path):
    """åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    if not os.path.exists(path):
        os.makedirs(path)

def fetch_lineup(match_id):
    """ä»APIè·å–é˜µå®¹æ•°æ®"""
    url = API_URL_TEMPLATE.format(match_id=match_id)
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ è¯·æ±‚å¤±è´¥: {e}")
        return None

def calculate_hash(file_path):
    """è®¡ç®—å·²æœ‰æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
    if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
        return None
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def compute_hash_for_data(data):
    """è®¡ç®—æ–°æ•°æ®çš„å“ˆå¸Œå€¼"""
    return hashlib.md5(str(data).encode()).hexdigest()

def find_not_started_rounds():
    """æ‰«æ CSV æ–‡ä»¶ï¼Œæ‰¾å‡ºæ‰€æœ‰åŒ…å« Not started æˆ– Postponed çŠ¶æ€çš„è½®æ¬¡"""
    not_started_rounds = set()
    
    for file_name in os.listdir(ROUND_DIR):
        if not file_name.endswith(".csv"):
            continue

        round_number = int(file_name.split(".")[0])
        file_path = os.path.join(ROUND_DIR, file_name)
        
        with open(file_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                status = row.get("Status", "").strip()
                if status == "Not started" or status == "Postponed":
                    not_started_rounds.add(round_number)
                    break  # åªè¦è¯¥è½®æ¬¡ä¸­æœ‰ä¸€åœºæ˜¯ Not started/Postponedï¼Œå°±è®°å½•è¯¥è½®

    return sorted(not_started_rounds)

def compute_update_rounds(not_started_rounds):
    """åŸºäº Not started è½®æ¬¡è®¡ç®—éœ€è¦æ›´æ–°çš„è½®æ¬¡ï¼ˆå‰å 2 è½®ï¼‰"""
    update_rounds = set()

    for round_number in not_started_rounds:
        for offset in range(-2, 3):  # å‘å‰2è½®ï¼Œå‘å2è½®
            new_round = round_number + offset
            if 1 <= new_round <= 38:  # é™åˆ¶åœ¨ 1-38 è½®èŒƒå›´å†…
                update_rounds.add(new_round)

    return sorted(update_rounds)

def process_match(round_number, match_id, status):
    """å¤„ç†å•åœºæ¯”èµ›çš„é˜µå®¹æ•°æ®"""
    round_path = os.path.join(LINEUP_DIR, str(round_number))
    create_directory(round_path)
    
    file_path = os.path.join(round_path, f"{match_id}.csv")

    # å¦‚æœæ¯”èµ›å°šæœªå¼€å§‹ï¼Œåˆ›å»ºç©ºæ–‡ä»¶
    if status != "Ended":
        open(file_path, 'w').close()  # åˆ›å»ºç©ºCSVæ–‡ä»¶
        print(f"Match {match_id} (Round {round_number}) not started, empty file created.")
        return
    
    lineup_data = fetch_lineup(match_id)
    if not lineup_data:
        print(f"âŒ Failed to fetch lineup for match {match_id}. Adding to retry queue.")
        failed_matches.append((round_number, match_id, status))
        return
    
    # è®¡ç®—æ–°æ•°æ®çš„å“ˆå¸Œå€¼
    new_hash = compute_hash_for_data(lineup_data)
    existing_hash = calculate_hash(file_path)

    if existing_hash == new_hash:
        print(f"âœ… Match {match_id} (Round {round_number}) lineup unchanged, skipping.")
        return

    # å†™å…¥æ–°çš„æ•°æ®
    with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Match ID", "Team", "Player ID", "Player Name", "Position", "Jersey Number", "Height", "Country", "Date of Birth", "Substitute", "Total Pass", "Accurate Pass", "Rating", "AverageX", "AverageY"])
        
        for team_key in ["home", "away"]:
            team_data = lineup_data.get(team_key, {})
            team_name = team_data.get("name", team_key.capitalize())
            players = team_data.get("players", [])
            
            for player_entry in players:
                player = player_entry.get("player", {})
                stats = player_entry.get("statistics", {})

                # æå–æ­£ç¡®çš„ averageX å’Œ averageY
                avg_x = player_entry.get("averageX", "Unknown")
                avg_y = player_entry.get("averageY", "Unknown")

                row = [
                    match_id,
                    team_name,
                    player.get("id", "Unknown"),  # æ–°å¢çƒå‘˜ ID
                    player.get("name", "Unknown"),
                    player.get("position", "Unknown"),
                    player.get("jerseyNumber", "Unknown"),
                    player.get("height", "Unknown"),
                    player.get("country", {}).get("name", "Unknown"),
                    player.get("dateOfBirthTimestamp", "Unknown"),
                    player_entry.get("substitute", False),
                    stats.get("totalPass", "Unknown"),
                    stats.get("accuratePass", "Unknown"),
                    stats.get("rating", "Unknown"),
                    avg_x,
                    avg_y
                ]
                writer.writerow(row)
    
    print(f"ğŸ”„ Match {match_id} (Round {round_number}) lineup updated.")

def retry_failed_matches():
    """é‡è¯•å¤±è´¥çš„æ¯”èµ›æŠ“å–"""
    global failed_matches
    max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

    for attempt in range(1, max_retries + 1):
        if not failed_matches:
            return  # å¦‚æœæ²¡æœ‰å¤±è´¥çš„æ¯”èµ›ï¼Œæå‰è¿”å›

        print(f"\nğŸ”„ é‡æ–°å°è¯•è·å– {len(failed_matches)} åœºå¤±è´¥çš„æ¯”èµ› (ç¬¬ {attempt}/{max_retries} æ¬¡)...\n")

        remaining_failures = []
        for round_number, match_id, status in failed_matches:
            print(f"Retrying match {match_id} (Round {round_number})...")
            lineup_data = fetch_lineup(match_id)
            
            if lineup_data:
                process_match(round_number, match_id, status)
            else:
                print(f"âŒ Match {match_id} still failed, will retry later.")
                remaining_failures.append((round_number, match_id, status))

        failed_matches = remaining_failures  # æ›´æ–°å¤±è´¥åˆ—è¡¨
        if failed_matches:
            time.sleep(5)  # ä¼‘çœ  5 ç§’å†è¯•ä¸‹ä¸€è½®
        else:
            print("âœ… æ‰€æœ‰å¤±è´¥çš„æ¯”èµ›éƒ½æˆåŠŸè·å–ï¼")
            return

    if failed_matches:
        print(f"âš ï¸ ä»ç„¶æœ‰ {len(failed_matches)} åœºæ¯”èµ›å¤±è´¥ï¼Œå»ºè®®æ‰‹åŠ¨æ£€æŸ¥: {failed_matches}")

def main():
    """ä¸»å‡½æ•°ï¼šéå†æ‰€æœ‰è½®æ¬¡ï¼Œè·å–æ¯”èµ›é˜µå®¹æ•°æ®"""
    print("ğŸ” Scanning for Not started and Postponed rounds...")
    not_started_rounds = find_not_started_rounds()
    print(f"ğŸ“ Not started/Postponed Rounds: {not_started_rounds}")

    update_rounds = compute_update_rounds(not_started_rounds)
    print(f"ğŸ”„ Rounds to update: {update_rounds}")

    for round_number in update_rounds:
        round_path = os.path.join(ROUND_DIR, f"{round_number}.csv")
        
        with open(round_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                match_id = row["Match ID"].strip()
                status = row["Status"].strip()
                process_match(round_number, match_id, status)

    # è¿è¡Œå®Œæ‰€æœ‰æ¯”èµ›åï¼Œé‡æ–°å°è¯•å¤±è´¥çš„æ¯”èµ›
    retry_failed_matches()

if __name__ == "__main__":
    main()
